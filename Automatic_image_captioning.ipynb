{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Automatic_image_captioning",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyP+r7FBYsDBvQYw3K7/ibVq",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jaindivij12/Automatic_image_captioning/blob/main/Automatic_image_captioning.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wXq8eqMeOXSD",
        "outputId": "39f13d86-fcbd-4e74-e5b3-7d56eb6c4f6e"
      },
      "source": [
        "from google.colab import drive\n",
        "\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jjUTyVvFNmg5"
      },
      "source": [
        "import numpy as np\n",
        "from numpy import array\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "import string\n",
        "import glob\n",
        "from time import time\n",
        "from PIL import Image\n",
        "import pickle\n",
        "from keras.applications.inception_v3 import InceptionV3\n",
        "from keras.models import Model\n",
        "from keras.preprocessing import image\n",
        "from keras.applications.inception_v3 import preprocess_input"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "syT1wJcAO37m",
        "outputId": "59ae25ab-56d6-4842-b4f3-a19fcf3511b9"
      },
      "source": [
        "def load_doc(filename):\n",
        "\tfile = open(filename, 'r')\n",
        "\ttext = file.read()\n",
        "\tfile.close()\n",
        "\treturn text\n",
        "\n",
        "filename = \"/content/drive/MyDrive/flicker8k/Flickr_Data/Flickr_TextData/Flickr8k.token.txt\"\n",
        "doc = load_doc(filename)\n",
        "print(doc[:300])\n"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1000268201_693b08cb0e.jpg#0\tA child in a pink dress is climbing up a set of stairs in an entry way .\n",
            "1000268201_693b08cb0e.jpg#1\tA girl going into a wooden building .\n",
            "1000268201_693b08cb0e.jpg#2\tA little girl climbing into a wooden playhouse .\n",
            "1000268201_693b08cb0e.jpg#3\tA little girl climbing the s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oIPqsaivPNp_",
        "outputId": "7b449208-6f6b-49d6-cdfc-476ac58633da"
      },
      "source": [
        "\n",
        "def load_descriptions(doc):\n",
        "\tmapping = dict()\n",
        "\t# process lines\n",
        "\tfor line in doc.split('\\n'):\n",
        "\t\t# split line by white space\n",
        "\t\ttokens = line.split()\n",
        "\t\tif len(line) < 2:\n",
        "\t\t\tcontinue\n",
        "\t\t# take the first token as the image id, the rest as the description\n",
        "\t\timage_id, image_desc = tokens[0], tokens[1:]\n",
        "\t\t# extract filename from image id\n",
        "\t\timage_id = image_id.split('.')[0]\n",
        "\t\t# convert description tokens back to string\n",
        "\t\timage_desc = ' '.join(image_desc)\n",
        "\t\t# create the list if needed\n",
        "\t\tif image_id not in mapping:\n",
        "\t\t\tmapping[image_id] = list()\n",
        "\t\t# store description\n",
        "\t\tmapping[image_id].append(image_desc)\n",
        "\treturn mapping\n",
        "\n",
        "# parse descriptions\n",
        "descriptions = load_descriptions(doc)\n",
        "print('Loaded: %d ' % len(descriptions))\n"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loaded: 8092 \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FWm1fDOKT_2G",
        "outputId": "d986c040-b165-4a30-f850-255281dd52de"
      },
      "source": [
        "list(descriptions.keys())[20:25]"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['1024138940_f1fefbdce1',\n",
              " '102455176_5f8ead62d5',\n",
              " '1026685415_0431cbf574',\n",
              " '1028205764_7e8df9a2ea',\n",
              " '1030985833_b0902ea560']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "84C5DYfMVKei",
        "outputId": "1c07a366-9226-4888-bf2e-991a7d9ba387"
      },
      "source": [
        "descriptions['1024138940_f1fefbdce1']"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Two different breeds of brown and white dogs play on the beach .',\n",
              " 'Two dogs are making a turn on a soft sand beach .',\n",
              " 'Two dogs playing in the sand at the beach .',\n",
              " 'Two dogs playing together on a beach .',\n",
              " 'Two large tan dogs play along a sandy beach .']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zrLfOtZ_WI2m"
      },
      "source": [
        "We do basic cleaning step, which includes upper case letters to lower case letters and remove punctuation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2v2FMei1VPZe"
      },
      "source": [
        "def clean_descriptions(descriptions):\n",
        "\t# prepare translation table for removing punctuation\n",
        "\ttable = str.maketrans('', '', string.punctuation)\n",
        "\tfor key, desc_list in descriptions.items():\n",
        "\t\tfor i in range(len(desc_list)):\n",
        "\t\t\tdesc = desc_list[i]\n",
        "\t\t\t# tokenize\n",
        "\t\t\tdesc = desc.split()\n",
        "\t\t\t# convert to lower case\n",
        "\t\t\tdesc = [word.lower() for word in desc]\n",
        "\t\t\t# remove punctuation from each token\n",
        "\t\t\tdesc = [w.translate(table) for w in desc]\n",
        "\t\t\t# remove hanging 's' and 'a'\n",
        "\t\t\tdesc = [word for word in desc if len(word)>1]\n",
        "\t\t\t# remove tokens with numbers in them\n",
        "\t\t\tdesc = [word for word in desc if word.isalpha()]\n",
        "\t\t\t# store as string\n",
        "\t\t\tdesc_list[i] =  ' '.join(desc)\n",
        "\n",
        "# clean descriptions\n",
        "clean_descriptions(descriptions)"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Tck4ls0sYvVx",
        "outputId": "617bcace-50c7-4a6e-eaae-04d704c03fe1"
      },
      "source": [
        "# convert the loaded descriptions into a vocabulary of words\n",
        "def to_vocabulary(descriptions):\n",
        "\t# build a list of all description strings\n",
        "\tall_desc = set()\n",
        "\tfor key in descriptions.keys():\n",
        "\t\t[all_desc.update(d.split()) for d in descriptions[key]]\n",
        "\treturn all_desc\n",
        "\n",
        "# summarize vocabulary\n",
        "vocabulary = to_vocabulary(descriptions)\n",
        "print('Original Vocabulary Size: %d' % len(vocabulary))"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Original Vocabulary Size: 8763\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_2QAgMS4k8x0"
      },
      "source": [
        "# save descriptions to file, one per line\n",
        "def save_descriptions(descriptions, filename):\n",
        "\tlines = list()\n",
        "\tfor key, desc_list in descriptions.items():\n",
        "\t\tfor desc in desc_list:\n",
        "\t\t\tlines.append(key + ' ' + desc)\n",
        "\tdata = '\\n'.join(lines)\n",
        "\tfile = open(filename, 'w')\n",
        "\tfile.write(data)\n",
        "\tfile.close()\n",
        "\n",
        "save_descriptions(descriptions, 'descriptions.txt')"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qJ9ZE8bplqd_",
        "outputId": "1d66b80c-2c25-4ee1-aaef-f039e75ee6c7"
      },
      "source": [
        "# load a pre-defined list of photo identifiers\n",
        "def load_set(filename):\n",
        "\tdoc = load_doc(filename)\n",
        "\tdataset = list()\n",
        "\t# process line by line\n",
        "\tfor line in doc.split('\\n'):\n",
        "\t\t# skip empty lines\n",
        "\t\tif len(line) < 1:\n",
        "\t\t\tcontinue\n",
        "\t\t# get the image identifier\n",
        "\t\tidentifier = line.split('.')[0]\n",
        "\t\tdataset.append(identifier)\n",
        "\treturn set(dataset)\n",
        "\n",
        "# load training dataset (6K)\n",
        "filename = '/content/drive/MyDrive/flicker8k/Flickr_Data/Flickr_TextData/Flickr_8k.trainImages.txt'\n",
        "train = load_set(filename)\n",
        "print('Dataset: %d' % len(train))"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Dataset: 6000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S8Qi8SYYmpms"
      },
      "source": [
        "# Create a list of all image names in the directory\n",
        "images='/content/drive/MyDrive/flicker8k/Flickr_Data/Images/'\n",
        "img = glob.glob(images + '*?.jpg')"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "idoL-pbdwBSD"
      },
      "source": [
        "# Below file conatains the names of images to be used in train data\n",
        "train_images_file = '/content/drive/MyDrive/flicker8k/Flickr_Data/Flickr_TextData/Flickr_8k.trainImages.txt'\n",
        "# Read the train image names in a set\n",
        "train_images = set(open(train_images_file, 'r').read().strip().split('\\n'))\n",
        "\n",
        "# Create a list of all the training images with their full path names\n",
        "train_img = []\n",
        "\n",
        "for i in img: # img is list of full path names of all images\n",
        "    if i[len(images):] in train_images: # Check if the image belongs to training set\n",
        "        train_img.append(i) # Add it to the list of train images"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6ZaYZ9SQw5HK"
      },
      "source": [
        "# Below file conatains the names of images to be used in test data\n",
        "test_images_file = '/content/drive/MyDrive/flicker8k/Flickr_Data/Flickr_TextData/Flickr_8k.testImages.txt'\n",
        "# Read the validation image names in a set# Read the test image names in a set\n",
        "test_images = set(open(test_images_file, 'r').read().strip().split('\\n'))\n",
        "\n",
        "# Create a list of all the test images with their full path names\n",
        "test_img = []\n",
        "\n",
        "for i in img: # img is list of full path names of all images\n",
        "    if i[len(images):] in test_images: # Check if the image belongs to test set\n",
        "        test_img.append(i) # Add it to the list of test images"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j7KF4YpgxIyZ",
        "outputId": "57b5910c-a2ee-42a3-fd74-d0b90975236c"
      },
      "source": [
        "# load clean descriptions into memory\n",
        "def load_clean_descriptions(filename, dataset):\n",
        "\t# load document\n",
        "\tdoc = load_doc(filename)\n",
        "\tdescriptions = dict()\n",
        "\tfor line in doc.split('\\n'):\n",
        "\t\t# split line by white space\n",
        "\t\ttokens = line.split()\n",
        "\t\t# split id from description\n",
        "\t\timage_id, image_desc = tokens[0], tokens[1:]\n",
        "\t\t# skip images not in the set\n",
        "\t\tif image_id in dataset:\n",
        "\t\t\t# create list\n",
        "\t\t\tif image_id not in descriptions:\n",
        "\t\t\t\tdescriptions[image_id] = list()\n",
        "\t\t\t# wrap description in tokens\n",
        "\t\t\tdesc = 'startseq ' + ' '.join(image_desc) + ' endseq'\n",
        "\t\t\t# store\n",
        "\t\t\tdescriptions[image_id].append(desc)\n",
        "\treturn descriptions\n",
        "\n",
        "# descriptions\n",
        "train_descriptions = load_clean_descriptions('descriptions.txt', train)\n",
        "print('Descriptions: train=%d' % len(train_descriptions))"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Descriptions: train=6000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jz5slqG7xixw"
      },
      "source": [
        "def preprocess(image_path):\n",
        "    # Convert all the images to size 299x299 as expected by the inception v3 model\n",
        "    img = image.load_img(image_path, target_size=(299, 299))\n",
        "    # Convert PIL image to numpy array of 3-dimensions\n",
        "    x = image.img_to_array(img)\n",
        "    # Add one more dimension\n",
        "    x = np.expand_dims(x, axis=0)\n",
        "    # preprocess the images using preprocess_input() from inception module\n",
        "    x = preprocess_input(x)\n",
        "    return x"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "enXZFOJP0S0R",
        "outputId": "ab7d5e74-ebfa-4237-f988-d780ba074d8c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# Load the inception v3 model\n",
        "model = InceptionV3(weights='imagenet')"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/inception_v3/inception_v3_weights_tf_dim_ordering_tf_kernels.h5\n",
            "96116736/96112376 [==============================] - 1s 0us/step\n",
            "96124928/96112376 [==============================] - 1s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bIgbeBsg0vlu"
      },
      "source": [
        "# Create a new model, by removing the last layer (output layer) from the inception v3\n",
        "model_new = Model(model.input, model.layers[-2].output)"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "InaKdXf81RCQ"
      },
      "source": [
        "# Function to encode a given image into a vector of size (2048, )\n",
        "def encode(image):\n",
        "    image = preprocess(image) # preprocess the image\n",
        "    fea_vec = model_new.predict(image) # Get the encoding vector for the image\n",
        "    fea_vec = np.reshape(fea_vec, fea_vec.shape[1]) # reshape from (1, 2048) to (2048, )\n",
        "    return fea_vec"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xayPJ3IG4Hdq",
        "outputId": "72851382-2223-415b-ad82-510322dcf77b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# Call the funtion to encode all the train images\n",
        "# This will take a while on CPU - Execute this only once\n",
        "start = time()\n",
        "encoding_train = {}\n",
        "for img in train_img:\n",
        "    encoding_train[img[len(images):]] = encode(img)\n",
        "print(\"Time taken in seconds =\", time()-start)"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Time taken in seconds = 2778.4130561351776\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F4sciw0s4LLV"
      },
      "source": [
        "# Save the bottleneck train features to disk\n",
        "with open(\"/content/drive/MyDrive/flicker8k/Flickr_Data/Pickle_Divij/encoded_train_images.pkl\", \"wb\") as encoded_pickle:\n",
        "    pickle.dump(encoding_train, encoded_pickle)"
      ],
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PahaC7Z8DduJ",
        "outputId": "98bb70a1-7972-4aa5-e14f-308fd97a725b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# Call the funtion to encode all the test images - Execute this only once\n",
        "start = time()\n",
        "encoding_test = {}\n",
        "for img in test_img:\n",
        "    encoding_test[img[len(images):]] = encode(img)\n",
        "print(\"Time taken in seconds =\", time()-start)"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Time taken in seconds = 505.5837936401367\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J7dh96zRuxhJ"
      },
      "source": [
        "# Save the bottleneck test features to disk\n",
        "with open(\"/content/drive/MyDrive/flicker8k/Flickr_Data/Pickle_Divij/encoded_test_images.pkl\", \"wb\") as encoded_pickle:\n",
        "    pickle.dump(encoding_test, encoded_pickle)"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WCm1zGKMwvua",
        "outputId": "965956e8-46a7-4adb-c15f-1a07e9b76ede",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "train_features = pickle.load(open(\"/content/drive/MyDrive/flicker8k/Flickr_Data/Pickle_Divij/encoded_train_images.pkl\", \"rb\"))\n",
        "print('Photos: train=%d' % len(train_features))"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Photos: train=6000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uEtEt39CxROE",
        "outputId": "c369dafe-2afe-4eac-cd7b-b81ddc8be237",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# Create a list of all the training captions\n",
        "all_train_captions = []\n",
        "for key, val in train_descriptions.items():\n",
        "    for cap in val:\n",
        "        all_train_captions.append(cap)\n",
        "len(all_train_captions)"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "30000"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YlJvLYK9adnz",
        "outputId": "ea1bed27-5fac-402b-9e10-af87b04688cb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# Consider only words which occur at least 10 times in the corpus\n",
        "word_count_threshold = 10\n",
        "word_counts = {}\n",
        "nsents = 0\n",
        "for sent in all_train_captions:\n",
        "    nsents += 1\n",
        "    for w in sent.split(' '):\n",
        "        word_counts[w] = word_counts.get(w, 0) + 1\n",
        "\n",
        "vocab = [w for w in word_counts if word_counts[w] >= word_count_threshold]\n",
        "print('preprocessed words %d -> %d' % (len(word_counts), len(vocab)))"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "preprocessed words 7578 -> 1651\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WK4LYDaRag4N"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}